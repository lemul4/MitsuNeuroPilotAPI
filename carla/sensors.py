#!/usr/bin/env python
"""
CARLA Manual Control with RGB, Semantic Segmentation Cameras and Additional Sensors
"""

import glob
import os
import sys
import argparse
import time
import threading
import queue
from datetime import datetime
import math
import pygame
import numpy as np
import cv2
import matplotlib
import open3d as o3d

try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla

# ---------------- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ----------------
CARLA_FPS = 40
SENSOR_TICK = '0.1'  # 10 —Ñ–ø—Å 

latest_seg_frame = None
seg_frame_lock = threading.Lock()

latest_rgb_frame = None
rgb_frame_lock = threading.Lock()

latest_depth_frame = None
depth_frame_lock = threading.Lock()

latest_speed_kmh = 0.0
latest_game_time = "00:00:00"

recording_enabled = False
recording_dirs = {}
control_csv_file = None
gnss_file = None
obstacle_file = None
collision_file = None
lane_invasion_file = None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –±—É—Ñ–µ—Ä—ã –¥–ª—è —Å–æ–±—ã—Ç–∏–π
collision_events = {}          
lane_invasion_events = {}      
first_sensor_tick_frame = None  

# –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–æ–≤
file_write_queue = queue.Queue()
file_write_thread = None  

# –¶–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏
VIRIDIS = np.array(matplotlib.colormaps['plasma'].colors)
LABEL_COLORS = np.array([
    (0, 0, 0),           # Unlabeled
    (128, 64, 128),      # Road
    (244, 35, 232),      # Sidewalk
    (70, 70, 70),        # Building
    (102, 102, 156),     # Wall
    (190, 153, 153),     # Fence
    (153, 153, 153),     # Pole
    (250, 170, 30),      # Traffic Light
    (220, 220, 0),       # Traffic Sign
    (107, 142, 35),      # Vegetation
    (152, 251, 152),     # Terrain
    (70, 130, 180),      # Sky
    (220, 20, 60),       # Pedestrian
    (255, 0, 0),         # Rider
    (0, 0, 142),         # Car
    (0, 0, 70),          # Truck
    (0, 60, 100),        # Bus
    (0, 80, 100),        # Train
    (0, 0, 230),         # Motorcycle
    (119, 11, 32),       # Bicycle
    (110, 190, 160),     # Static
    (170, 120, 50),      # Dynamic
    (55, 90, 80),        # Other
    (45, 60, 150),       # Water
    (157, 234, 50),      # Road Line
    (81, 0, 81),         # Ground
    (150, 100, 100),     # Bridge
    (230, 150, 140),     # Rail Track
    (180, 165, 180)      # Guard Rail
]) / 255.0

# ---------------- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ ----------------

def write_line(file_obj, text):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —Ñ–∞–π–ª –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –±—É—Ñ–µ—Ä.
    """
    file_obj.write(text)
    file_obj.flush()

def file_writer():
    """
    –§—É–Ω–∫—Ü–∏—è-–≤–æ—Ä–∫–µ—Ä, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.
    """
    while True:
        task = file_write_queue.get()
        if task is None:
            break
        func, args, kwargs = task
        try:
            func(*args, **kwargs)
        except Exception as e:
            print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞:", e)
        file_write_queue.task_done()

# ---------------- Helper Functions ----------------

def get_frame_from_image(image, color_converter=None):
    if color_converter:
        image.convert(color_converter)
    array = np.frombuffer(image.raw_data, dtype=np.uint8)
    array = array.reshape((image.height, image.width, 4))
    return array[:, :, :3]

# ---------------- Callback –¥–ª—è Lidar ----------------

def semantic_lidar_callback(point_cloud, point_list):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö Lidar —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π.
    –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –æ—Å—å Y –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ Open3D.
    """
    data = np.frombuffer(point_cloud.raw_data, dtype=np.dtype([
        ('x', np.float32), ('y', np.float32), ('z', np.float32),
        ('CosAngle', np.float32), ('ObjIdx', np.uint32), ('ObjTag', np.uint32)]))
    points = np.array([data['y'], data['x'], data['z']]).T

    labels = np.array(data['ObjTag'])
    labels[labels == 24] = 1 
    mask = ~np.isin(labels, [11, 23])
    filtered_points = points[mask]
    filtered_labels = labels[mask]

    colors = LABEL_COLORS[filtered_labels]
    point_list.points = o3d.utility.Vector3dVector(filtered_points)
    point_list.colors = o3d.utility.Vector3dVector(colors)
    
    if recording_enabled:
        filtered_data = data[mask]
        filename = os.path.join(recording_dirs['lidar_semantic'], f"lidar_{point_cloud.frame:06d}.npy")
        file_write_queue.put((np.save, (filename, filtered_data), {}))

def generate_lidar_bp(world):
    lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast_semantic')
    lidar_bp.set_attribute('upper_fov', '15.0')
    lidar_bp.set_attribute('lower_fov', '-25.0')
    lidar_bp.set_attribute('channels', '32')
    lidar_bp.set_attribute('range', '50')
    lidar_bp.set_attribute('rotation_frequency', '20.0')
    lidar_bp.set_attribute('points_per_second', '300000')
    lidar_bp.set_attribute('role_name', 'lidar_semantic')
    lidar_bp.set_attribute('sensor_tick', SENSOR_TICK)
    return lidar_bp

def add_open3d_axis(vis):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Å–µ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≤ Open3D-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä.
    –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç —Ç–æ—á–µ–∫, –ª–∏–Ω–∏–π –∏ —Ü–≤–µ—Ç–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    """
    axis = o3d.geometry.LineSet()
    pts = np.array([
        [0.0, 0.0, 0.0],
        [1.0, 0.0, 0.0],
        [0.0, 1.0, 0.0],
        [0.0, 0.0, 1.0]
    ])
    axis.points = o3d.utility.Vector3dVector(pts)
    axis.lines = o3d.utility.Vector2iVector(np.array([
        [0, 1],
        [0, 2],
        [0, 3]
    ]))
    axis.colors = o3d.utility.Vector3dVector(np.array([
        [1.0, 0.0, 0.0],
        [0.0, 1.0, 0.0],
        [0.0, 0.0, 1.0]
    ]))
    vis.add_geometry(axis)

# ---------------- Callback —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–µ–Ω—Å–æ—Ä–æ–≤ ----------------

def process_segmentation_image(image):
    global first_sensor_tick_frame, latest_seg_frame
    # –§–∏–∫—Å–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —Å–µ–Ω—Å–æ—Ä–Ω—ã–π –∫–∞–¥—Ä, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–¥–∞–Ω
    if first_sensor_tick_frame is None:
        first_sensor_tick_frame = image.frame
    frame = get_frame_from_image(image, carla.ColorConverter.CityScapesPalette)
    with seg_frame_lock:
        latest_seg_frame = frame
    if recording_enabled:
        filename = os.path.join(recording_dirs['semantic_cam'], f"semantic_{image.frame:06d}.png")
        file_write_queue.put((cv2.imwrite, (filename, frame), {}))

def process_rgb_image(image):
    frame = get_frame_from_image(image)
    with rgb_frame_lock:
        global latest_rgb_frame
        latest_rgb_frame = frame

def process_depth_image(image):
    frame = get_frame_from_image(image, carla.ColorConverter.LogarithmicDepth)
    with depth_frame_lock:
        global latest_depth_frame
        latest_depth_frame = frame
    if recording_enabled:
        filename = os.path.join(recording_dirs['depth_cam'], f"depth_{image.frame:06d}.png")
        file_write_queue.put((cv2.imwrite, (filename, frame), {}))

def process_gnss_data(data):
    msg = "GNSS: Latitude: {:.6f}, Longitude: {:.6f}, Altitude: {:.2f}".format(
        data.latitude, data.longitude, data.altitude)
    print(msg)
    if recording_enabled:
        line = f"{data.frame},{data.timestamp:.3f},{data.latitude},{data.longitude},{data.altitude}\n"
        file_write_queue.put((write_line, (gnss_file, line), {}))

def process_obstacle_data(event):
    actor_str = event.other_actor.type_id if event.other_actor is not None else "Unknown"
    print(f"üöß Obstacle event: other_actor={actor_str}, distance={event.distance:.2f}")
    if recording_enabled:
        line = f"{event.frame},{event.timestamp:.3f},{actor_str},{event.distance:.2f}\n"
        file_write_queue.put((write_line, (obstacle_file, line), {}))

def process_collision_data(event):
    global collision_events
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏–µ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏—è –≤ –±—É—Ñ–µ—Ä, –≤–º–µ—Å—Ç–æ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
    if event.frame not in collision_events:
        collision_events[event.frame] = []
    collision_events[event.frame].append(event)

def process_lane_invasion_data(event):
    global lane_invasion_events
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏–µ –≤—ã–µ–∑–¥–∞ –∏–∑ –ø–æ–ª–æ—Å—ã –≤ –±—É—Ñ–µ—Ä, –≤–º–µ—Å—Ç–æ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
    if event.frame not in lane_invasion_events:
        lane_invasion_events[event.frame] = []
    lane_invasion_events[event.frame].append(event)


# ---------------- Display Loop (cv2 –æ–∫–Ω–∞) ----------------

def display_loop():
    cv2.startWindowThread()
    cv2.namedWindow("Semantic Segmentation", cv2.WINDOW_NORMAL)
    cv2.namedWindow("Depth Camera", cv2.WINDOW_NORMAL)

    last_seg_frame = None

    while True:
        with seg_frame_lock:
            seg_frame = latest_seg_frame.copy() if latest_seg_frame is not None else None
        with depth_frame_lock:
            depth_frame = latest_depth_frame.copy() if latest_depth_frame is not None else None

        if seg_frame is not None:
            last_seg_frame = seg_frame

        if last_seg_frame is not None:
            cv2.imshow("Semantic Segmentation", last_seg_frame)
        if depth_frame is not None:
            cv2.imshow("Depth Camera", depth_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        time.sleep(0.005)
    cv2.destroyAllWindows()

# ---------------- Cleanup Function ----------------

def cleanup(actors, vis):
    for actor in actors:
        try:
            actor.stop()
        except Exception:
            pass
        try:
            actor.destroy()
        except Exception:
            pass
    try:
        vis.destroy_window()
    except Exception:
        pass
    cv2.destroyAllWindows()
    pygame.quit()
    file_write_queue.put(None)
    if file_write_thread is not None:
        file_write_thread.join()
    global control_csv_file, gnss_file, obstacle_file, collision_file, lane_invasion_file
    if recording_enabled:
        if control_csv_file: control_csv_file.close()
        if gnss_file: gnss_file.close()
        if obstacle_file: obstacle_file.close()
        if collision_file: collision_file.close()
        if lane_invasion_file: lane_invasion_file.close()

# ---------------- Main Function ----------------

def main():
    global recording_enabled, recording_dirs, control_csv_file, gnss_file, obstacle_file, collision_file, lane_invasion_file, file_write_thread
    argparser = argparse.ArgumentParser(
        description="CARLA Manual Control with RGB, Semantic Segmentation Cameras and Additional Sensors")
    argparser.add_argument('--host', default='127.0.0.1',
                           help='IP-–∞–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ —Å–∏–º—É–ª—è—Ç–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 127.0.0.1)')
    argparser.add_argument('-p', '--port', type=int, default=2000,
                           help='TCP-–ø–æ—Ä—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2000)')
    argparser.add_argument('--disable-seg', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å —Å–µ–Ω—Å–æ—Ä —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏')
    argparser.add_argument('--disable-rgb', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å RGB –∫–∞–º–µ—Ä—É')
    argparser.add_argument('--disable-depth', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å –¥–∞—Ç—á–∏–∫ –≥–ª—É–±–∏–Ω—ã')
    argparser.add_argument('--disable-lidar', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å Lidar —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π')
    argparser.add_argument('--disable-gnss', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å GNSS —Å–µ–Ω—Å–æ—Ä')
    argparser.add_argument('--disable-obstacle', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å –¥–∞—Ç—á–∏–∫ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π')
    argparser.add_argument('--disable-collision', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å –¥–∞—Ç—á–∏–∫ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–π')
    argparser.add_argument('--disable-laneinvasion', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å –¥–∞—Ç—á–∏–∫ –≤—ã–µ–∑–¥–∞ –∏–∑ –ø–æ–ª–æ—Å—ã')
    # –ù–æ–≤—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö
    argparser.add_argument('--record-data', action='store_true', help='–í–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤ –∏ vehicle control')
    args = argparser.parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç —É–∫–∞–∑–∞–Ω
    recording_enabled = args.record_data
    if recording_enabled:
        base_record_dir = os.path.join("recordings", datetime.now().strftime("%Y%m%d_%H%M%S"))
        os.makedirs(base_record_dir, exist_ok=True)
        recording_dirs = {
            'lidar_semantic': os.path.join(base_record_dir, "lidar_semantic"),
            'semantic_cam': os.path.join(base_record_dir, "semantic_cam"),
            'depth_cam': os.path.join(base_record_dir, "depth_cam"),
            'gnss': os.path.join(base_record_dir, "gnss"),
            'obstacle_sensor': os.path.join(base_record_dir, "obstacle_sensor"),
            'collision_sensor': os.path.join(base_record_dir, "collision_sensor"),
            'lane_invasion_sensor': os.path.join(base_record_dir, "lane_invasion_sensor"),
        }
        for d in recording_dirs.values():
            os.makedirs(d, exist_ok=True)
        control_csv_path = os.path.join(base_record_dir, "vehicle_control.csv")
        control_csv_file = open(control_csv_path, "w")
        control_csv_file.write("frame,timestamp,throttle,steer,brake,reverse,speed_kmh\n")
        gnss_csv_path = os.path.join(recording_dirs['gnss'], "gnss.csv")
        gnss_file = open(gnss_csv_path, "w")
        gnss_file.write("frame,timestamp,latitude,longitude,altitude\n")
        obstacle_csv_path = os.path.join(recording_dirs['obstacle_sensor'], "obstacle.csv")
        obstacle_file = open(obstacle_csv_path, "w")
        obstacle_file.write("frame,timestamp,other_actor,distance\n")
        collision_csv_path = os.path.join(recording_dirs['collision_sensor'], "collision.csv")
        collision_file = open(collision_csv_path, "w")
        collision_file.write("frame,timestamp,other_actor\n")
        lane_invasion_csv_path = os.path.join(recording_dirs['lane_invasion_sensor'], "lane_invasion.csv")
        lane_invasion_file = open(lane_invasion_csv_path, "w")
        lane_invasion_file.write("frame,timestamp,type,lane_change\n")
        print(f"–ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤–∫–ª—é—á–µ–Ω–∞. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ {base_record_dir}")
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏
        file_write_thread = threading.Thread(target=file_writer, daemon=True)
        file_write_thread.start()

    client = carla.Client(args.host, args.port)
    client.set_timeout(10.0)
    world = client.load_world('Town05_Opt',)

    settings = world.get_settings()
    settings.no_rendering_mode = True
    settings.synchronous_mode = True
    settings.fixed_delta_seconds = 1.0 / CARLA_FPS
    world.apply_settings(settings)

    blueprint_library = world.get_blueprint_library()

    vehicle_bp = blueprint_library.filter('vehicle.*')[0]
    vehicle_bp.set_attribute('role_name', 'actor')
    spawn_points = world.get_map().get_spawn_points()
    if not spawn_points:
        sys.exit("–û—à–∏–±–∫–∞: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ—á–µ–∫ —Å–ø–∞–≤–Ω–∞.")
    vehicle = world.spawn_actor(vehicle_bp, spawn_points[0])
    print("–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ –∑–∞—Å–ø–∞–≤–Ω–µ–Ω–æ.")

    actors = []

    if not args.disable_seg:
        seg_cam_bp = blueprint_library.find('sensor.camera.semantic_segmentation')
        seg_cam_bp.set_attribute('image_size_x', '768')
        seg_cam_bp.set_attribute('image_size_y', '432')
        seg_cam_bp.set_attribute('fov', '90')
        seg_cam_bp.set_attribute('sensor_tick', SENSOR_TICK)
        seg_cam_bp.set_attribute('lens_circle_falloff', '1.2')
        seg_cam_bp.set_attribute('lens_circle_multiplier', '1.0')
        seg_cam_bp.set_attribute('lens_k', '-0.2')
        seg_cam_bp.set_attribute('lens_kcube', '0.01')
        seg_cam_bp.set_attribute('role_name', 'semantic_cam')
        seg_cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
        seg_cam = world.spawn_actor(seg_cam_bp, seg_cam_transform, attach_to=vehicle)
        seg_cam.listen(process_segmentation_image)
        actors.append(seg_cam)
    else:
        print("–°–µ–Ω—Å–æ—Ä —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_rgb:
        rgb_cam_bp = blueprint_library.find('sensor.camera.rgb')
        rgb_cam_bp.set_attribute('image_size_x', '1920')
        rgb_cam_bp.set_attribute('image_size_y', '1080')
        rgb_cam_bp.set_attribute('fov', '105')
        rgb_cam_bp.set_attribute('sensor_tick', str(1 / CARLA_FPS))
        rgb_cam_bp.set_attribute('lens_circle_falloff', '1.2')
        rgb_cam_bp.set_attribute('lens_circle_multiplier', '1.0')
        rgb_cam_bp.set_attribute('lens_k', '-0.2')
        rgb_cam_bp.set_attribute('lens_kcube', '0.01')
        rgb_cam_bp.set_attribute('role_name', 'rgb_camera')
        rgb_cam_transform = carla.Transform(
            carla.Location(x=0.25, y=-0.31, z=1.35),
            carla.Rotation(pitch=0, yaw=0, roll=0)
        )
        rgb_cam = world.spawn_actor(rgb_cam_bp, rgb_cam_transform, attach_to=vehicle)
        rgb_cam.listen(process_rgb_image)
        actors.append(rgb_cam)
    else:
        print("RGB –∫–∞–º–µ—Ä–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")

    if not args.disable_lidar:
        lidar_bp = generate_lidar_bp(world)
        lidar_transform = carla.Transform(carla.Location(x=-0.5, z=2.4))
        lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=vehicle)
        point_list = o3d.geometry.PointCloud()
        lidar.listen(lambda data: semantic_lidar_callback(data, point_list))
        actors.append(lidar)
    else:
        print("Lidar —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_gnss:
        gnss_bp = blueprint_library.find('sensor.other.gnss')
        gnss_bp.set_attribute('sensor_tick', SENSOR_TICK)
        gnss_bp.set_attribute('role_name', 'gnss')
        gnss_transform = carla.Transform(carla.Location(x=0, y=0, z=2.8))
        gnss_sensor = world.spawn_actor(gnss_bp, gnss_transform, attach_to=vehicle)
        gnss_sensor.listen(process_gnss_data)
        actors.append(gnss_sensor)
    else:
        print("GNSS —Å–µ–Ω—Å–æ—Ä –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_depth:
        depth_cam_bp = blueprint_library.find('sensor.camera.depth')
        depth_cam_bp.set_attribute('image_size_x', '768')
        depth_cam_bp.set_attribute('image_size_y', '432')
        depth_cam_bp.set_attribute('fov', '90')
        depth_cam_bp.set_attribute('sensor_tick', SENSOR_TICK)
        depth_cam_bp.set_attribute('lens_circle_falloff', '1.2')
        depth_cam_bp.set_attribute('lens_circle_multiplier', '1.0')
        depth_cam_bp.set_attribute('lens_k', '-0.2')
        depth_cam_bp.set_attribute('lens_kcube', '0.01')
        depth_cam_bp.set_attribute('role_name', 'depth_cam')
        depth_cam_transform = carla.Transform(carla.Location(x=1.5, y=0.3, z=2.4))
        depth_cam = world.spawn_actor(depth_cam_bp, depth_cam_transform, attach_to=vehicle)
        depth_cam.listen(process_depth_image)
        actors.append(depth_cam)
    else:
        print("–î–∞—Ç—á–∏–∫ –≥–ª—É–±–∏–Ω—ã –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_obstacle:
        obstacle_bp = blueprint_library.find('sensor.other.obstacle')
        obstacle_bp.set_attribute('sensor_tick', SENSOR_TICK)
        obstacle_bp.set_attribute('debug_linetrace', 'False')
        obstacle_bp.set_attribute('distance', '3')
        obstacle_bp.set_attribute('only_dynamics', 'False')
        obstacle_bp.set_attribute('role_name', 'obstacle_sensor')
        obstacle_transform = carla.Transform(carla.Location(x=2.5, z=1.0))
        obstacle_detector = world.spawn_actor(obstacle_bp, obstacle_transform, attach_to=vehicle)
        obstacle_detector.listen(process_obstacle_data)
        actors.append(obstacle_detector)
    else:
        print("–î–∞—Ç—á–∏–∫ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_collision:
        collision_bp = blueprint_library.find('sensor.other.collision')
        collision_bp.set_attribute('role_name', 'collision_sensor')
        collision_transform = carla.Transform()
        collision_sensor = world.spawn_actor(collision_bp, collision_transform, attach_to=vehicle)
        collision_sensor.listen(process_collision_data)
        actors.append(collision_sensor)
    else:
        print("–î–∞—Ç—á–∏–∫ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω.")

    if not args.disable_laneinvasion:
        lane_invasion_bp = blueprint_library.find('sensor.other.lane_invasion')
        lane_invasion_bp.set_attribute('role_name', 'lane_invasion_sensor')
        lane_invasion_transform = carla.Transform()
        lane_invasion_sensor = world.spawn_actor(lane_invasion_bp, lane_invasion_transform, attach_to=vehicle)
        lane_invasion_sensor.listen(process_lane_invasion_data)
        actors.append(lane_invasion_sensor)
    else:
        print("–î–∞—Ç—á–∏–∫ –≤—ã–µ–∑–¥–∞ –∏–∑ –ø–æ–ª–æ—Å—ã –æ—Ç–∫–ª—é—á–µ–Ω.")

    actors.append(vehicle)

    display_thread = threading.Thread(target=display_loop)
    display_thread.daemon = True
    display_thread.start()

    if not args.disable_lidar:
        vis = o3d.visualization.Visualizer()
        vis.create_window(window_name='Carla Lidar', width=500, height=500)
        render_opt = vis.get_render_option()
        render_opt.background_color = [0.05, 0.05, 0.05]
        render_opt.point_size = 1
        render_opt.show_coordinate_frame = True
        add_open3d_axis(vis)
    else:
        vis = o3d.visualization.Visualizer()

    pygame.init()
    pygame.joystick.init()
    display_width, display_height = 800, 600
    screen = pygame.display.set_mode((display_width, display_height), pygame.RESIZABLE)
    pygame.display.set_caption("CARLA Manual Control & RGB Camera")
    clock = pygame.time.Clock()
    font = pygame.font.SysFont(None, 24)

    joystick = None
    if pygame.joystick.get_count() > 0:
        joystick = pygame.joystick.Joystick(0)
        joystick.init()
        print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:", joystick.get_name())
    else:
        print("–†—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã.")

    control = carla.VehicleControl()
    control.throttle = 0.0
    control.steer = 0.0
    control.brake = 0.0
    control.reverse = False

    NITRO_BOOST = 3
    frame = 0
    dt0 = datetime.now()
    
    try:
        while True:
            if not args.disable_lidar:
                ctr = vis.get_view_control()
                ctr.set_lookat([0, 0, 0])
                ctr.set_up([0, 1, 0])
                ctr.set_zoom(0.3)
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    raise KeyboardInterrupt
                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE:
                        raise KeyboardInterrupt
                elif event.type == pygame.VIDEORESIZE:
                    display_width, display_height = event.size
                    screen = pygame.display.set_mode((display_width, display_height), pygame.RESIZABLE)

            keys = pygame.key.get_pressed()
            control.throttle = 0.0
            control.steer = 0.0
            control.brake = 0.0
            keyboard_used = False

            if keys[pygame.K_UP]:
                control.reverse = False
                control.throttle = 0.7
                keyboard_used = True
            elif keys[pygame.K_DOWN]:
                control.reverse = True
                control.throttle = 0.7
                keyboard_used = True

            if keys[pygame.K_LEFT]:
                control.steer = -0.3
                keyboard_used = True
            elif keys[pygame.K_RIGHT]:
                control.steer = 0.3
                keyboard_used = True

            if joystick is not None and not keyboard_used:
                steer_axis = joystick.get_axis(0)
                gas_axis = joystick.get_axis(1)
                brake_axis = joystick.get_axis(2)
                control.steer = steer_axis * 0.25
                throttle = max(0.0, min(1.0, (1 - gas_axis) / 2))
                brake = max(0.0, min(1.0, (1 - brake_axis) / 2))
                if brake < 0.0001 < throttle:
                    brake = 0.0
                if brake > 0.0001:
                    throttle = 0.0
                control.brake = brake
                if joystick.get_button(6):
                    throttle *= NITRO_BOOST
                    throttle = min(throttle, 1.0)
                control.throttle = throttle
                control.reverse = joystick.get_button(0)

            vehicle.apply_control(control)

            if frame == 2 and not args.disable_lidar:
                vis.add_geometry(point_list)
            if not args.disable_lidar:
                vis.update_geometry(point_list)
                vis.poll_events()
                vis.update_renderer()

            velocity = vehicle.get_velocity()
            speed = math.sqrt(velocity.x ** 2 + velocity.y ** 2 + velocity.z ** 2) * 3.6
            global latest_speed_kmh
            latest_speed_kmh = speed
            snapshot = world.get_snapshot()
            game_seconds = int(snapshot.timestamp.elapsed_seconds)
            hours = game_seconds // 3600
            minutes = (game_seconds % 3600) // 60
            seconds = game_seconds % 60
            global latest_game_time
            latest_game_time = f"{hours:02d}:{minutes:02d}:{seconds:02d}"

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏—è –∏ –≤—ã–µ–∑–¥–∞ –∏–∑ –ø–æ–ª–æ—Å—ã –Ω–∞ "—Å–µ–Ω—Å–æ—Ä–Ω–æ–º" –∫–∞–¥—Ä–µ
            current_frame = snapshot.frame
            if first_sensor_tick_frame is not None:
                frames_per_sensor_tick = int(CARLA_FPS * float(SENSOR_TICK))
                if (current_frame - first_sensor_tick_frame) % frames_per_sensor_tick == 0:
                    current_time = snapshot.timestamp.elapsed_seconds

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–π:
                    all_collision_events = []
                    for key in list(collision_events.keys()):
                        if key <= current_frame:
                            all_collision_events.extend(collision_events[key])
                            del collision_events[key]
                    unique_collisions = {}
                    for event in all_collision_events:
                        actor_type = event.other_actor.type_id if event.other_actor is not None else "Unknown"
                        if actor_type not in unique_collisions:
                            unique_collisions[actor_type] = event
                    for actor_type, event in unique_collisions.items():
                        print("üí• Collision with:", actor_type)
                        if recording_enabled:
                            line = f"{current_frame},{current_time:.3f},{actor_type}\n"
                            file_write_queue.put((write_line, (collision_file, line), {}))

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–µ–∑–¥–∞ –∏–∑ –ø–æ–ª–æ—Å—ã:
                    all_lane_events = []
                    for key in list(lane_invasion_events.keys()):
                        if key <= current_frame:
                            all_lane_events.extend(lane_invasion_events[key])
                            del lane_invasion_events[key]
                    unique_lane_invasions = {}
                    for event in all_lane_events:
                        for lm in event.crossed_lane_markings:
                            lm_type = str(lm.type)
                            lm_lane_change = str(lm.lane_change)
                            key = (lm_type, lm_lane_change)
                            if key not in unique_lane_invasions:
                                unique_lane_invasions[key] = (lm_type, lm_lane_change)
                    for key, value in unique_lane_invasions.items():
                        lm_type,  lm_lane_change = value
                        print("üö¶ Lane invasion detected:", lm_type, lm_lane_change)
                        if recording_enabled:
                            line = f"{current_frame},{current_time:.3f},{lm_type},{lm_lane_change}\n"
                            file_write_queue.put((write_line, (lane_invasion_file, line), {}))

                    # –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö vehicle control
                    if recording_enabled:
                        line = f"{snapshot.frame},{snapshot.timestamp.elapsed_seconds:.3f},{control.throttle},{control.steer},{control.brake},{control.reverse},{latest_speed_kmh}\n"
                        file_write_queue.put((write_line, (control_csv_file, line), {}))

            if not args.disable_rgb:
                with rgb_frame_lock:
                    rgb_frame = latest_rgb_frame.copy() if latest_rgb_frame is not None else None

                if rgb_frame is not None:
                    rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2RGB)
                    surface = pygame.image.frombuffer(rgb_frame.tobytes(), (rgb_frame.shape[1], rgb_frame.shape[0]), "RGB")
                    surface = pygame.transform.scale(surface, (display_width, display_height))
                    screen.blit(surface, (0, 0))
                else:
                    screen.fill((30, 30, 30))
            else:
                screen.fill((30, 30, 30))
                text_surface = font.render("RGB –∫–∞–º–µ—Ä–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞", True, (255, 255, 255))
                screen.blit(text_surface, (10, 10))

            overlay_lines = [
                f"Speed: {latest_speed_kmh:.1f} km/h",
                f"Time: {latest_game_time}"
            ]
            y = 10
            for line in overlay_lines:
                text_surface = font.render(line, True, (255, 255, 255))
                screen.blit(text_surface, (display_width - text_surface.get_width() - 10, y))
                y += text_surface.get_height() + 5

            pygame.display.flip()
            world.tick()

            process_time = datetime.now() - dt0
            fps = 1.0 / process_time.total_seconds() if process_time.total_seconds() > 0 else 0
            sys.stdout.write(f'\rFPS: {fps:.2f} ')
            sys.stdout.flush()
            dt0 = datetime.now()
            frame += 1
            clock.tick(CARLA_FPS)
    except KeyboardInterrupt:
        print("\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    finally:
        cleanup(actors, vis)

if __name__ == '__main__':
    main()
